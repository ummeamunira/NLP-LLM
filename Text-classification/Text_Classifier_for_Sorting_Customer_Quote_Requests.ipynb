{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN37FQchV1TZI0pTAMFEnD8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ummeamunira/NLP-LLM/blob/main/Text-classification/Text_Classifier_for_Sorting_Customer_Quote_Requests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a manufacturing company, the sales team receives numerous customer quote requests via emails and chats. These requests need to be categorized by product type (e.g., valves, pumps) and by complexity (simple or complex). Manually sorting these requests is time-consuming and inefficient. A text classifier can automate this process, enabling sales representatives to prioritize and respond faster, ultimately boosting sales conversion rates.\n",
        "\n",
        "**Goal:**\n",
        "Develop a text classifier to automatically categorize customer quote requests by product type and complexity. This will help sales reps prioritize and manage their workload more efficiently."
      ],
      "metadata": {
        "id": "efou7BUQdjTZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Collection:**\n",
        "\n",
        "Collect a dataset of customer quote requests, including emails and chat transcripts. Label each request with the corresponding product type and complexity."
      ],
      "metadata": {
        "id": "33-wtZb_eTqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example dataset\n",
        "data = {\n",
        "    'request': [\n",
        "        \"I need a quote for industrial valves.\",\n",
        "        \"Looking for pricing on high-capacity pumps.\",\n",
        "        \"Can you provide a detailed quote for custom-made valves?\",\n",
        "        \"Need information on replacement parts for pumps.\",\n",
        "        \"Requesting a simple quote for standard valves.\",\n",
        "        \"Urgently need a quote for complex pump systems.\",\n",
        "        \"Looking for quotes on basic valves.\",\n",
        "        \"Can you provide pricing on advanced pump models?\"\n",
        "    ],\n",
        "    'product_type': [\n",
        "        \"valves\", \"pumps\", \"valves\", \"pumps\",\n",
        "        \"valves\", \"pumps\", \"valves\", \"pumps\"\n",
        "    ],\n",
        "    'complexity': [\n",
        "        \"simple\", \"simple\", \"complex\", \"simple\",\n",
        "        \"simple\", \"complex\", \"simple\", \"complex\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "BmBvJVrhfNIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing:**\n",
        "\n",
        "Clean and preprocess the text data, including tokenization, removing stop words, and converting text to numerical features using techniques like TF-IDF."
      ],
      "metadata": {
        "id": "CqlUBnCSeXTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Split the data into training and testing sets for both classifiers\n",
        "X_train, X_test, y_train_product, y_test_product = train_test_split(df['request'], df['product_type'], test_size=0.2, random_state=42)\n",
        "_, _, y_train_complexity, y_test_complexity = train_test_split(df['request'], df['complexity'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize the text data using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n"
      ],
      "metadata": {
        "id": "tVpPyCT3fPrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Training:**\n",
        "\n",
        "Train machine learning models on the preprocessed data to classify requests by product type and complexity."
      ],
      "metadata": {
        "id": "jemLte-5eZ6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Train the product type classifier\n",
        "product_model = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer(stop_words='english')),\n",
        "    ('classifier', LogisticRegression(random_state=42))\n",
        "])\n",
        "\n",
        "product_model.fit(X_train, y_train_product)\n",
        "\n",
        "# Train the complexity classifier\n",
        "complexity_model = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer(stop_words='english')),\n",
        "    ('classifier', LogisticRegression(random_state=42))\n",
        "])\n",
        "\n",
        "complexity_model.fit(X_train, y_train_complexity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "29c-OZR3fTpx",
        "outputId": "6f1ed313-a5fd-4636-cf6b-7e0f9b424cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer', TfidfVectorizer(stop_words='english')),\n",
              "                ('classifier', LogisticRegression(random_state=42))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer(stop_words=&#x27;english&#x27;)),\n",
              "                (&#x27;classifier&#x27;, LogisticRegression(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer(stop_words=&#x27;english&#x27;)),\n",
              "                (&#x27;classifier&#x27;, LogisticRegression(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation:**\n",
        "\n",
        "Evaluate the models using appropriate metrics like accuracy, precision, recall, and F1-score."
      ],
      "metadata": {
        "id": "zlnSgXZ3edJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the categories of the test set for product type\n",
        "y_pred_product = product_model.predict(X_test)\n",
        "print(\"Product Type Classification Report:\")\n",
        "print(classification_report(y_test_product, y_pred_product))\n",
        "\n",
        "# Predict the categories of the test set for complexity\n",
        "y_pred_complexity = complexity_model.predict(X_test)\n",
        "print(\"Complexity Classification Report:\")\n",
        "print(classification_report(y_test_complexity, y_pred_complexity))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHtQixq2fhb6",
        "outputId": "9abf9c7f-fd4a-48f3-cd23-5eb0928f6a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product Type Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       pumps       0.00      0.00      0.00       2.0\n",
            "      valves       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00       2.0\n",
            "   macro avg       0.00      0.00      0.00       2.0\n",
            "weighted avg       0.00      0.00      0.00       2.0\n",
            "\n",
            "Complexity Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     complex       0.00      0.00      0.00         1\n",
            "      simple       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deployment:**\n",
        "\n",
        "Deploy the models to classify new incoming requests in real-time."
      ],
      "metadata": {
        "id": "j6zdNAhqegQR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEGS73aqdRyb"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Save the trained models\n",
        "joblib.dump(product_model, 'product_classifier_model.pkl')\n",
        "joblib.dump(complexity_model, 'complexity_classifier_model.pkl')\n",
        "\n",
        "# Load the models\n",
        "product_model = joblib.load('product_classifier_model.pkl')\n",
        "complexity_model = joblib.load('complexity_classifier_model.pkl')\n",
        "\n",
        "@app.route('/classify', methods=['POST'])\n",
        "def classify():\n",
        "    data = request.get_json(force=True)\n",
        "    request_text = data['request']\n",
        "\n",
        "    # Predict the product type and complexity\n",
        "    product_type = product_model.predict([request_text])[0]\n",
        "    complexity = complexity_model.predict([request_text])[0]\n",
        "\n",
        "    return jsonify({'product_type': product_type, 'complexity': complexity})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the classifier, send a POST request to the /classify endpoint with a customer quote request:"
      ],
      "metadata": {
        "id": "v37S7t-Mfqsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "curl -X POST -H \"Content-Type: application/json\" -d '{\"request\": \"Looking for pricing on high-capacity pumps.\"}' http://127.0.0.1:5000/classify\n"
      ],
      "metadata": {
        "id": "eDfFH7HQfpy-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}